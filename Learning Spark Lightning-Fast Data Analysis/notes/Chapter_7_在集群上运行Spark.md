# Chapter_7 在集群上运行Spark

    Spark可以在各种各样的集群管理器（Hadoop YARN、 Apache Mesos，还有Spark自带的独立集群管理器）上运行，所以Spark应用既能够适应专用集群，又能用于共享的云计算环境。

## 1. Spark应用的运行时架构

    概念：
        1. 驱动器节点(进程)
        2. 执行器节点(进程)
    分布式集群环境下，Spark应用运行时是采用主从结构，有一个主节点负责中央协调，调度各个分布式的工作节点。这个负责中央协调的主节点称为驱动器(Driver)节点，运行驱动器进程，与之对应的工作节点称为执行器(executor)节点，运行执行器进程。驱动器节点可以和大量的执行器节点进行通信， 它们也都作为独立的 Java 进程运行。驱动器节点和所有的执行器节点一起被称为一个 Spark 应用（application）。Spark 应用通过一个叫作集群管理器（Cluster Manager）的外部服务在集群中的机器上启动。 Spark 自带的集群管理器被称为独立集群管理器。

1.  驱动器节点：

        驱动器节点是执行Spark应用程序中main()方法的进程。它执行用户编写的用来创建SparkContext、创建RDD，以及进行RDD的转化操作和行动操作的代码。实际我们在运行Spark-shell时，就是启动了一个驱动器进程，Spark-shell总是会预先加载一个叫sc的SparkContext对象。驱动器进程一旦终止，Spark应用也就结束了。
        驱动器进程在Spark应用中有两个职责：
        1. 把用户程序转为任务
        Spark驱动程序负责把用户程序转为多个物理执行单元，这些单元被称为任务（task）。
        从上层来看，所有的 Spark 程序都遵循同样的结构：程序从输入数据创建一系列RDD，再使用转化操作派生出新的RDD，最后使用行动操作收集或存储结果RDD中的数据。 Spark程序其实是隐式地创建出了一个由操作组成的逻辑上的有向无环图（Directed Acyclic Graph，简称 DAG）。当驱动器程序运行时，它会把这个逻辑图转为物理执行计划。Spark会对逻辑执行计划作一些优化，比如将连续的映射转为流水线化执行，将多个操作合并到一个步骤中等。 这样Spark就把逻辑计划转为一系列步骤（stage）。而每个步骤又由多个任务组成。这些任务会被打包并送到集群中。任务是Spark中最小的工作单元，用户程序通常要启动成百上千的独立任务。
        2. 为执行器节点调度任务
        有了物理执行计划之后，Spark驱动器程序必须在各执行器进程间协调任务的调度。执行器进程启动后，会向驱动器进程注册自己。因此，驱动器进程始终对应用中所有的执行器节点有完整的记录。每个执行器节点代表一个能够处理任务和存储RDD数据的进程。Spark驱动器程序会根据当前的执行器节点集合，尝试把所有任务基于数据所在位置分配给合适的执行器进程。当任务执行时，执行器进程会把缓存数据存储起来，而驱动器进程同样会跟踪这些缓存数据的位置，并且利用这些位置信息来调度以后的任务，以尽量减少数据的网络传输。

        此外，驱动器程序会将一些 Spark 应用的运行时的信息通过网页界面呈现出来，默认在端口4040上。 

2.  执行器节点
        Spark 执行器节点是一种工作进程，负责在 Spark 作业中运行任务，任务间相互独立。Spark 应用启动时， 执行器节点就被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在(注意：随着Spark版本的演进，该说法已不准确，在较新版本的Spark中，已能够支持动态资源分配特性，该特性允许在Spark应用运行期间，根据工作负载实现executor占用资源的动态申请和回收)。如果有执行器节点发生了异常或崩溃， Spark 应用也可以继续执行。执行器进程有两大作用： 第一，它们负责运行组成 Spark 应用的任务，并将结果返回给驱动器进程；第二，它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。 RDD 是直接缓存在执行器进程内的，因此任务可以在运行时充分利用缓存数据加速运算。

    驱动器节点和执行器节点是如何启动的呢？ Spark依赖于集群管理器来启动执行器节点，而在某些特殊情况下（Spark应用以集群模式提交，Driver进程运行在集群内部节点中时），也依赖集群管理器来启动驱动器节点。

## 2. 启动Spark应用程序

    不论使用的是哪一种集群管理器，你都可以使用Spark提供的统一脚本spark-submit将你的应用提交到那种集群管理器上。通过不同的配置选项，spark-submit可以连接到相应的集群管理器上，并控制应用所使用的资源数量。在使用某些特定集群管理器时，spark-submit也可以将驱动器节点运行在集群内部（比如一个YARN的工作节点）。但对于其他的集群管理器，驱动器节点只能被运行在本地机器上。

    在集群上运行一个Spark应用的基本过程如下：
        (1) 用户通过 spark-submit 脚本提交应用。
        (2) spark-submit 脚本启动驱动器程序，调用用户定义的 main() 方法。
        (3) 驱动器程序与集群管理器通信，申请资源以启动执行器节点。
        (4) 集群管理器为驱动器程序启动执行器节点。
        (5) 驱动器进程执行用户应用中的操作。 根据程序中所定义的对 RDD 的转化操作和行动操作，驱动器节点把工作以任务的形式发送到执行器进程。
        (6) 任务在执行器程序中进行计算并保存结果。
        (7) 如果驱动器程序的 main() 方法退出，或者调用了 SparkContext.stop()，驱动器程序会终止执行器进程，并且通过集群管理器释放资源。
