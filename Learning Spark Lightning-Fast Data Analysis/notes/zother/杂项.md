# 杂项

## 1. YARN上Hadoop MapReduce中job和Spark中job的区别：

>1. MapReduce中的一个job会启动一个ApplicationMaster，对应yarn上的一个application；
>2. Spark中的一个app才会启动一个ApplicationMaster，对应yarn上的一个application；
>3. MapReduce中一个job对应的就是一个MR对儿的执行；
>4. Spark中的一个job对应的则是一个行动操作的执行，而一个app中通常有多个行动操作，也即包含多个job；
>5. MapReduce的一个job是一个资源申请的单位，每个job都要单独做一套配置；
>6. Spark中的一个app才是一个资源申请的单位，app中各个行动操作的job共享一套app配置；
